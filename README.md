<!--#     The TensorFlow Microcontroller Challenge    -->
   <h1>:robot: :mechanical_arm: IA para Espacios interactivos :mechanical_arm: :robot:</h1>

<!-- PROJECT LOGO -->
<br />
<p align="center">
  <a href="https://projecthub.arduino.cc/projects/">
    <img src="media_bot/intro.png" alt="Logo" width="720">
  </a>
  <br />

  <img src="https://img.shields.io/github/languages/top/fullmakeralchemist/k_way_challenge_repo?style=for-the-badge" alt="License" height="25">
  <img src="https://img.shields.io/github/last-commit/fullmakeralchemist/k_way_challenge_repo?style=for-the-badge" alt="GitHub last commit" height="25">


  <a href="https://www.linkedin.com/in/fullmakeralchemist/">
    <img src="https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555" alt="LinkedIn" height="25">
  </a>
  <!--<a href="https://projecthub.arduino.cc/projects/">
    <img src="https://img.shields.io/badge/Arduino-Arduino%20Project%20Hub-blue" alt="Twitter" height="25">
  </a>-->
   <h3 align="center">IA para Espacios interactivos proyecto final para Bootcamp de Python Avanzado</h3>
  <p align="center">
    Empoderando el Arte
    <!--<br />
    <a href="https://projecthub.arduino.cc/projects/"><strong>View the project¬ª</strong></a>
    <br />-->
  </p>
  <p align="center">
  <!--<a href="https://projecthub.arduino.cc/projects/">
  </a>-->
  </p>
  <br />
</p>
<br />

<!-- ABOUT THE PROJECT -->
## About The Project

<!-- [![Tiny ML in Mapping Dance](https://i9.ytimg.com/vi/3YUVTDTo-Zk/mq1.jpg?sqp=CNTs2IcG&rs=AOn4CLBiPsvQ2bGNVZvn_j-nJXj8d81hLA)](https://www.youtube.com/watch?v=3YUVTDTo-Zk) -->

Un dispositivo inteligente para identificar movimientos en un espacio interactivo y responder a estos con animaciones, retroiluminaci√≥n, m√∫sica y esculturas inteligentes. 
Este proyecto hace uso de un algoritmo de aprendizaje autom√°tico capaz de clasificar y detectar movimientos para identificar gestos asociados a trav√©s de un microcontrolador y un protocolo de comunicaci√≥n. 
Las esculturas inteligentes, iluminaci√≥n, m√∫sica y proyecci√≥n de video que se activan con cada gesto definido, crean una poderosa experiencia que resalta el incre√≠ble potencial de TinyML para las artes esc√©nicas.
Esto permite que el conjunto de elementos correspondiente se reproduzca cuando se realiz√≥ el movimiento correcto porque todos estos elementos interact√∫an para crear una nueva experiencia. 
Esto nos permite crear instalaciones interactivas, estas esculturas utilizan una combinaci√≥n de motores, sensores y otros dispositivos electr√≥nicos para crear una experiencia inmersiva e interactiva para el espectador. 
Pueden incluir proyecciones, sonido y otros elementos sensoriales asi como mas elementos de forma escalable para crear una experiencia completa.

<!-- Content of the repository -->
## Metodolog√≠a

Este proyecto est√° dise√±ado para abordar los desaf√≠os que enfrentan los profesionales en el campo del arte, particularmente en M√©xico, donde la asistencia a lugares culturales y artisticos tiene un aforo de bajo porcentaje en la poblacion. 
Los objetivos principales del proyecto son los siguientes:

1. Crear un modelo que detecte movimientos
2. El dispositivo del modelo se conecte por alg√∫n protocolo a la Raspberry
3. Usar la Raspberry como intermediario entre el dispositivo con el modelo y los actuadores
4. Que respondan por movimiento los actuadores
5. Que sea escalable

Los pasos de la metodolog√≠a utilizada son:

1. Selecci√≥n de Hardware y Sensores:
- Seleccionar cuidadosamente los dispositivos de hardware, como Arduino o Raspberry Pi, seg√∫n los requisitos del proyecto y las tarjetas que puedan ser compatibles.
2. Selecci√≥n de protocolos de comunicaci√≥n y librer√≠as:
- Identificar las herramientas como MQTT y Open Source software como Mosquitto que sean compatibles con Arduino, Raspberry y la comunicaci√≥n Bluetooth con las tarjetas Arduino Nano.
3. Desarrollo de Firmware y Configuraci√≥n del Dispositivo:
- Desarrollar el prototipo de software y hardware necesario para los dispositivos seleccionados, programando la recepci√≥n y transmisi√≥n de datos desde las tarjetas cuando detecten un movimiento en espec√≠fico.
4. Pruebas y Validaci√≥n del Sistema:
- Realizar pruebas exhaustivas del sistema en todas las etapas, desde la adquisici√≥n de datos hasta el env√≠o de las se√±ales para activar el sistema.

Al seguir esta metodolog√≠a, se espera que el proyecto logre su objetivo de activar los elementos que se pudieron integrar al proyecto.

### Creado con

Con cari√±o üíñ, motivaci√≥n para ayudar a otros üí™üèº Arduino, Edge Impulse y Python üêç, usando:

* Edge Impulse con su plataforma y su documentaci√≥n
* Arduino IDE y  Hardware
* Arduino Nano Nicla SENSE ME (con Bateria)
* Arduino Nano RP 2040
* Una [Raspberry Pi 4 4GB](https://www.raspberrypi.org/) 4 <img src="https://www.raspberrypi.org/homepage-9df4b/favicon.png" width="15">
* Alg√∫n proyector con conexi√≥n HDMI 
* Arduino Opla IoT Kit
* The MQTT [Mosquitto](https://mosquitto.org/) Broker
* The [Eclipse Paho](http://eclipse.org/paho/) MQTT Python client [library](https://pypi.org/project/paho-mqtt/)
* [PubSubClient library](https://github.com/knolleary/pubsubclient/archive/master.zip) in Arduino IDE for the ESP8266 Board
* Arduino IDE
* Alg√∫n dispositivo que pueda reproducir Spotify
* Robot de Legos en esta ocasi√≥n us√© un HAT de Raspberry que es compatible con Legos de motor

<!-- GETTING STARTED -->
## Getting Started

Para tener una copia local en funcionamiento, siga estos pasos:

### Prerrequisitos

Antes de descargar una copia a tu ambiente local necesitas tener o hacer los siguientes pasos. Esta es una lista de cosas que necesitas para que se ejecute el script y como instalar algunas de ellas. La primera de ellas es:

- Configurar Raspberry Pi OS para ejecutar el c√≥digo
- Configurar una m√°quina con el IDE de Arduino y sus librer√≠as as√≠ como los elementos necesarios para el c√≥digo de la tarjeta, obtener la librer√≠a de PubSubClient para usar MQTT en Tarjetas Arduino.
- Configurar el Edge Impulse CLI en Windows (Es lo que yo use) para crear tu dataset que servir√° para entrenar el modelo en este caso mi modelo ya est√° entrenado y listo para ser usado en Arduino. En caso de querer entrenar tu propio modelo dejare los pasos pero necesitas crear una cuenta en Edge Impulse documentaci√≥n de Edge Impulse.
- Setear Spotify en Raspberry PI OS para poder ejecutar comandos de Spotify developer.
- Entrenar el modelo en Edge Impulse.

Para esta secci√≥n en particular, supondr√© que ya tienes una Raspberry Pi configurada. Si no, tengo una gu√≠a en Medium para hacerlo [Getting started on Raspberry Pi 4](https://fullmakeralchemist.medium.com/setting-up-your-raspberry-pi-4-wireless-f51c16937d1e). 
Tambien necesitas tener git instalado en caso de que no te dejo una guia que hice en [Medium](https://fullmakeralchemist.medium.com/install-git-and-visual-studio-code-on-raspberry-pi-48d054fdee07) para hacerlo.
Para obtener una descripci√≥n general de la configuraci√≥n de Arduino Nicla Sense ME, puede consultar la Gu√≠a de Arduino en [Getting started with Arduino Nicla Sense ME](https://docs.arduino.cc/tutorials/nicla-sense-me/getting-started/).

Antes de instalar las librerias en Raspberry Pi, ejecute las siguientes l√≠neas de c√≥digo en la terminal Raspberry Pi:

```
sudo apt update
sudo apt upgrade
```
Despu√©s de actualizar escribiremos el siguiente comando para crear un Virtual Environment:

```
python -m venv env
source/env/bin/activate
```

Para tener el VLC que puede reproducir videos en Raspberry Pi hay que ejecutar: 
```
pip install python-vlc
```

Para instalar Mosquitto Broker, ingrese los siguientes comandos. Tendr√°s que escribir el comando y luego introducir "Y" cuando lo solicite y presionar Enter para confirmar la instalaci√≥n. Para hacer que Mosquitto se inicie autom√°ticamente al arrancar, ingrese:

```
sudo apt install -y mosquitto mosquitto-clients
```

Luego escriba el siguiente comando, tenemos que modificar un documento que se instal√≥ para habilitar el Broker MQTT como broker p√∫blico en su red WIFI local:

```
sudo nano¬†/etc/mosquitto/mosquitto.conf  
```

Ahora agrega las siguientes l√≠neas al final, sin modificar el resto del documento (Ctrl+x para guardar cambios):
```
listener 1883   
allow_anonymous true   
```

Despu√©s de guardar el documento, debe reiniciar Mosquitto Broker, ejecutar el siguiente comando y reiniciar la Raspberry Pi:
```
sudo systemctl restart mosquitto.service   

```
Adem√°s, para configurar el Broker para que se inicie cuando inicie su Raspberry, debe ejecutar el siguiente comando en la terminal:

```
sudo systemctl enable mosquitto.service
```

Una √∫ltima cosa para verificar si el broker Mosquitto se est√° ejecutando y disponible, ejecute en la terminal el comando:
```
mosquitto -v
```
Esto devuelve la versi√≥n de Mosquitto que se est√° ejecutando actualmente en su Raspberry Pi. deber√≠a ser 1.5.X o superior.

<center>
<img src="media_bot/mosquittov.png" width="60%">
</center>

#### Raspberry Pi direcci√≥n IP Address y paquete Paho

Para utilizar el broker Mosquitto m√°s adelante en sus proyectos, necesitar√° su direcci√≥n IP de Raspberry Pi. Para identificar su direcci√≥n IP de Raspberry Pi, escriba el siguiente comando en la ventana de su Terminal:
```
hostname -I
```
<center>
<img src="media_bot/iprasp.png" width="60%">
</center>

La libreria Paho proporciona una clase de cliente que permite que las aplicaciones se conecten a un broker MQTT para publicar mensajes, suscribirse a topics y recibir mensajes publicados. 
En este proyecto, el script de Python publicar√° mensajes en el broker para comunicarse con el Arduino Opl√° Kit para encender y apagar los GPIO para controlar las luces y ejecutar un sonido.
Para instalar paho-mqtt ejecute el siguiente comando:

```
pip install paho-mqtt
```

Tambi√©n tienes que instalar la biblioteca Bluepy para tener comunicaci√≥n con el Arduino Nicla Sense ME mediante Bluetooth: ‚Äã 

Este repositorio https://github.com/IanHarvey/bluepy contiene los pasos para instalarlo en caso de problemas revisa las demas opciones yo segui la siguiente:

Necesite instalarlo desde la fuente.

```
sudo apt-get install git build-essential libglib2.0-dev
git clone https://github.com/IanHarvey/bluepy.git
cd bluepy
python setup.py build
sudo python setup.py install
```
Luego ejecute el comando:

```
pip install bluepy   
```

Con eso tenemos configurada la Raspberry Pi para conectar mediante python un dispositivo que no entrega informacion.

Para controlar el Robot Lego con el HAT compatible con Arduino necesitas instalar la biblioteca LegoPi para Raspberry Pi:
```
sudo pip3 install buildhat   
```

Es necesario instalar la biblioteca Python para Spotify y luego podr√°s controlar la m√∫sica como desees con c√≥digo: 
```
pip install spotipy --upgrade   
```

Y esos son los pasos que seguiremos para configurar nuestra Raspberry Pi.

Ahora veamos la configuraci√≥n del IDE de Arduino.

### Setup Arduino IDE in Windows

Es hora de configurar todo en Windows (el sistema operativo que yo use) para entrenar el modelo y cargar los c√≥digos en los tableros que vamos a usar: 

En primer lugar vamos a configurar el IDE de Arduino para las 3 placas utilizadas en el proyecto. Despu√©s de instalar el IDE de Arduino en su computadora 
es necesario instalar en el administrador de placas, las dependendencias necesarias para cada placa, aqu√≠ est√°n los enlaces 
para ver la documentaci√≥n de Arduino como gu√≠a de inicio r√°pido para cada placa. 

- [Nicla Sense ME](https://docs.arduino.cc/software/ide-v1/tutorials/getting-started/cores/arduino-mbed_nicla)
- [Arduino Opl√° IoT Kit](https://opla.arduino.cc/?_gl=1*97vzvq*_ga*MjAwOTE1MTc1NS4xNjcyNDE0MTQx*_ga_NEXN8H46L5*MTY3NTA0MTA4NS43Ny4xLjE2NzUwNDEyNTcuMC4wLjA.)
- [Arduino Nano RP2040 Connect](https://docs.arduino.cc/software/ide-v1/tutorials/getting-started/cores/arduino-mbed_nano?_gl=1*j5d0ho*_ga*MjAwOTE1MTc1NS4xNjcyNDE0MTQx*_ga_NEXN8H46L5*MTY3NTA0MTA4NS43Ny4xLjE2NzUwNDEyNTcuMC4wLjA.)

Tambi√©n para el Arduino Nicla es necesario instalar la biblioteca Arduino_BHY2 de Arduino en el administrador de bibliotecas del IDE. 
Esta biblioteca permite utilizar todos los sensores de la placa. Para el Arduino Nicla es necesario instalar la biblioteca ArduinoBLE by Arduino en el administrador de bibliotecas del IDE. Esta biblioteca es para utilizar la conectividad Bluetooth en la placa.

Para la Placa RP2040 y el Kit Opl√° IoT es necesario instalar la biblioteca WiFiNINA de Arduino en el gestor de bibliotecas del IDE. 
Este es para conectividad WIFI. Para la Placa Opl√° IoT Kit es necesario instalar la biblioteca Arduino_MKRIoTCarrier de Arduino en el administrador de bibliotecas del IDE. Este es para el control del Carrier para las luces y sonidos con el timbre.

### Obteniendo la biblioteca MQTT para las placas Arduino
Para que Arduino Nano y Opl√° interact√∫en con el broker de Raspberry es necesario instalar PubSubClient [libreria](https://github.com/knolleary/pubsubclient). 
Esta biblioteca proporciona un cliente para enviar mensajes simples de publicaci√≥n/suscripci√≥n con un servidor que admite MQTT (b√°sicamente permite que su Arduino hable con un Broker MQTT). 
[Click aqui para descargar la libreria PubSubClient](https://github.com/knolleary/pubsubclient/archive/master.zip)
1. Deber√≠as tener una carpeta .zip en la carpeta de Descarga. Descomprime la carpeta .zip y deber√≠as obtener la carpeta pubsubclient-master. 
2. Cambia el nombre de la carpeta de pubsubclient-master a pubsubclient.
3. Mueve la carpeta pubsubclient a la carpeta de bibliotecas de instalaci√≥n de su IDE de Arduino. Luego, vuelve a abrir tu IDE de Arduino 
4. Finalmente tenemos todo configurado en nuestro IDE de Arduino y podemos comenzar a usar las placas, pero antes de hacerlo necesitamos configurar todo en nuestra m√°quina Windows para entrenar nuestro modelo con la plataforma Edge Impulse.

### Configuraci√≥n de la CLI de Edge Impulse en Windows
Necesitas tener una cuenta en Edge Impulse. 
Para instalar Edge Impulse CLI en Windows, sigue la documentaci√≥n detallada de [Edge Impulse](https://docs.edgeimpulse.com/docs/edge-impulse-cli/cli-installation). 
Ahora estamos listos para comenzar a entrenar nuestro modelo en caso de que quieras tener un modelo con movimientos diferentes a los m√≠os, pero te mostrar√© c√≥mo entreno mi modelo mas adelante aun faltan algunas configuraciones.

### Configurar Spotify en Raspberry

Primero necesitamos crear o iniciar sesi√≥n en el https://developer.spotify.com/ plataforma y lo primero que vamos a hacer es crear una aplicaci√≥n que sea realmente sencilla, luego de esto vamos a tener en el Dashboard nuestra aplicaci√≥n y tenemos que darle clic. Luego seremos redirigidos a la descripci√≥n general de la aplicaci√≥n y tendremos que seleccionar editar configuraci√≥n para agregar algunas URL: 

```
http://localhost:8888/callback   
http://localhost:8080  
```

Agregalas para redireccionar las URIs:

<center>
<img src="media_bot/3.png" width="60%">
</center>

Despu√©s de agregarlos, volvemos a la descripci√≥n general de nuestra aplicaci√≥n Nicla en el panel de desarrolladores, all√≠ podemos encontrar el ID del cliente y el Client Secret que necesitamos para el c√≥digo. Aseg√∫rate de copiar los valores. Para obtener la ID del dispositivo, que es una pieza importante para nuestro c√≥digo, necesitamos dos cosas: 
La m√°s f√°cil es reproducir en cualquier dispositivo, tel√©fono, computadora, altavoz inteligente o cualquier otro dispositivo que queramos usar para escuchar m√∫sica, reproducir cualquier lista de reproducci√≥n mientras. Al realizar este paso, necesitamos esto para detectar el dispositivo deseado y controlarlo a trav√©s de nuestro c√≥digo Python. 
El segundo ser√° ir a este enlace https://developer.spotify.com/console/get-users-available-devices/ en este enlace haremos clic en Obtener token, 
aseg√∫rarse de marcar la casilla de verificaci√≥n para user-read-playback-state y despu√©s de esto, haz clic en el token de solicitud.

<center>
<img src="media_bot/4.png" width="60%">
</center>

Haz clic en TRY IT y donde est√° el cuadro rojo en la imagen de abajo deber√≠a aparecer el "id": , ese es el valor que debes copiar, (no lo muestro porque es informaci√≥n sensible). 
Aseg√∫rate de que el nombre corresponda a su tel√©fono o dispositivo utilizado.

<center>
<img src="media_bot/5.png" width="60%">
</center>

Ahora que tenemos todo preparado en la plataforma de Desarrolladores, debemos regresar a nuestra Raspberry Pi y abrir nuestro editor. Us√© Thonny pero antes de usar nuestro c√≥digo final necesitamos ejecutar un c√≥digo anterior, solo para que Spotipy inicie sesi√≥n desde la Raspberry a nuestra cuenta de Spotify. 
Despu√©s de esto, el c√≥digo ya no solicitar√° iniciar sesi√≥n ni solicitara credenciales en el dispositivo en el que estamos ejecutando nuestro c√≥digo final. Una √∫ltima cosa, si desea utilizar una canci√≥n espec√≠fica, debe copiar el enlace de esa canci√≥n en Spotify. Opci√≥n en Spotify para copiar la canci√≥n como enlace. 

Aqu√≠ hay un ejemplo: 
https://open.spotify.com/track/**3h3XIdPa1W8NtxEw0TOQHb**si=cc4dd6b0ea0f41f6 
Entonces, en nuestro enlace marqu√© en negrita el c√≥digo que debes copiar del enlace y reemplazar la √∫ltima parte de esta l√≠nea c√≥digo.

```
uris=['spotify:track:3h3XIdPa1W8NtxEw0TOQHb']
```

Ahora puedes reproducir desde tu c√≥digo en Python cualquier canci√≥n que quieras. Copia, pega y ejecuta este c√≥digo:

```
import spotipy   
from spotipy.oauth2 import SpotifyOAuth   
from pprint import pprint   
device_id = "" #Put the values from your account   
client_id = ""#Put the values from your account   
client_secret = ""   
redirect_uri = "http://localhost:8080"   
scope = "user-read-playback-state,user-modify-playback-state"   
sp = spotipy.Spotify(   
	       auth_manager=spotipy.SpotifyOAuth(   
	         client_id=client_id,   
	         client_secret=client_secret,   
	         redirect_uri=redirect_uri,       
	         scope=scope, open_browser=False))   
sp.start_playback(device_id=device_id ,uris=['spotify:track:1o7D1gLUgpFR3eJfIgpSUx'])   
```

Cuando ejecutas el c√≥digo, proporciona un enlace en el que debes hacer clic y ah√≠ es donde te pedir√° que inicies sesi√≥n. El mismo enlace que envi√≥ debe copiarse y pegarse en un campo que te pide que pegues el enlace despu√©s de eso. Una vez todo configurado para usar Spotify con nuestro c√≥digo final, contin√∫a ejecutando el proyecto final. 

## Entrena el modelo en Edge Impulse

Segu√≠ todos los pasos en los casos de estudio destacados proporcionados por Edge Impulse y el que trataba sobre el movimiento fue [Arduino x K-Way - Outdoor Activity Tracker](https://docs.edgeimpulse.com/experts/featured-case-studies/arduino-kway-outdoor-activity-tracker)
lo √∫nico que necesito incluir es antes de escribir el comando 
edge-impulse-data-forwarder, debes cargar el siguiente a tu Arduino Nicla. [C√≥digo](https://github.com/Zalmotek/edge-impulse-arduino-k-way-outdoor-activity-tracker/blob/main/arduino/components/nicla_sense_ingestion_climbing/nicla_sense_ingestion_climbing.ino) proporcionado por el caso de estudio.

Una vez que lo hayas hecho, y cuando escribas el comando edge-impulse-data-forwarder te preguntar√° el nombre de las variables, debes asegurarte de que coincidan, as√≠ que copia y pega esto en la terminal donde te pregunta los nombres de las variables. 
y solo sigue la documentaci√≥n: 

```
accX, accY, accZ, gyrX, gyrY, gyrZ, rumbo, cabeceo, balanceo, rotX, rotY, rotZ, rotW   
```

Una vez que termines de dise√±ar tu modelo en la plataforma, debes ir a **Live Classification** y Datos de entrada con la funci√≥n **Start Sampling** antes de ir a Prueba de modelo. 
Un consejo para usar una funci√≥n que es realmente sorprendente de la plataforma Edge Impulse, es que te permite mapear las muestras que podr√≠an tener errores en tu modelo, las marcadas en rojo en el **Feature explorer** son las que tal vez deber√≠as eliminar del muestreo, y al seleccionarlos en el Explorador de funciones se mostrar√° el nombre para localizarlos y borrarlos tan f√°cilmente como hacer clic en los 3 puntos a la derecha de ese muestreo. 
Adem√°s, el **Feature explorer** te permite ver qu√© tan lejos est√°n las muestras entre s√≠. Un buen modelo tiene un grupo de muestras para un movimiento alejados entre s√≠, al menos para este proyecto para tener un modelo que no confunda un movimiento con otro debe tener los grupos alejados entre s√≠. 
Despu√©s de que la prueba de su modelo tenga una precisi√≥n igual o superior al 90 %, puedes proceder a la implementaci√≥n y exportar tu modelo como una biblioteca Arduino.

<center>
<img src="media_bot/6.png" width="60%">
</center>

Ahora podemos exportar como biblioteca seleccionando la opci√≥n, entonces no es necesario seleccionar una placa para Nicla Sense ME y por favor seleccione la casilla para optimizar el modelo, se exportar√° y ahora podr√° seguir los pasos para importarlo en Arduino IDE como una libreria. 
Y este es mi modelo en la plataforma Edge Impulse Studio que debes incluir en el IDE de Arduino como biblioteca. 

penduente
Tambi√©n puedes descargarlo como un archivo ZIP desde este [enlace](https://drive.google.com/file/d/1Xw_pMS1q8sWmX0Of4hZIFeWf8iHbAMMJ/view?usp=share_link). 
No olvides que necesitas los archivos de video para el proyector usados en este proyecto. Ve a este enlace para descargarlo y usarlo. 

<center>
<img src="media_bot/7.png" width="60%">
</center>

Ahora podemos ir a ejemplos, verificar la carpeta en la biblioteca con el nombre de nuestro modelo exportado desde Edge Impulse y seleccionar nicla_sense_fusion y ese es el archivo que vamos a modificar, pero primero debemos guardarlo como archivo para crear una copia. El ejemplo, ahora puedes probarlo para ver si los resultados son buenos y antes de probarlo, tenemos que borrar algunas l√≠neas del ejemplo para nuestro modelo de movimiento, marca debajo de las l√≠neas que debemos borrar.

<center>
<img src="media_bot/8.png" width="60%">
</center>

Borra las siguientes l√≠neas para preparar nuestro script Arduino, extraen valores de sensores que no necesitamos para el modelo creado: 

```
/* Private variables ------------------------------------------------------- */
Sensor temp(SENSOR_ID_TEMP);
Sensor baro(SENSOR_ID_BARO);
Sensor hum(SENSOR_ID_HUM);
Sensor gas(SENSOR_ID_GAS);
static float get_temperature(void){return temp.value();}
static float get_barrometric_pressure(void){return baro.value();}
static float get_humidity(void){return hum.value();}
static float get_gas(void){return gas.value();}
/** Used sensors value function connected to label name */
"temperature", &get_temperature,
"barometer", &get_barrometric_pressure,
"humidity", &get_humidity,
"gas", &get_gas,
Void setup
temp.begin();
baro.begin();
hum.begin();
gas.begin();
```

Una vez que tengamos listo este archivo podemos guardarlo y comenzar a comentar unas l√≠neas para centrarnos √∫nicamente en el clasificador: 

```
//ei_printf("\nStarting inferencing in 2 seconds...\r\n");
//ei_printf("Sampling...\r\n");
// print the predictions
//ei_printf("Predictions (DSP: %d ms., Classification: %d ms., Anomaly: %d ms.):\r\n",
//result.timing.dsp, result.timing.classification, result.timing.anomaly);
//ei_printf("%s: %.5f\r\n", result.classification[ix].label, result.classification[ix].value);
```

La √∫ltima modificaci√≥n que haremos es agregar estas l√≠neas en el bucle for que forma parte para imprimir las predicciones: 

<center>
<img src="media_bot/9.png" width="60%">
</center>

```
if(result.classification[ix].value>0.8){   
	         if(result.classification[ix].label=="jump"){   
	           Serial.print(1);   
	           }   
	         else if(result.classification[ix].label=="run"){   
	           Serial.print(2);   
	           }   
	         else if(result.classification[ix].label=="side"){   
	           Serial.print(3);   
	           }   
	         }   
```

Una vez que tengamos listo este archivo el Arduino se centrar√° en las salidas y podemos dejarlo como est√°, esto permitir√° que Arduino comunique las salidas del modelo en el puerto serial. 
Esto significa que si conectamos el Arduino a nuestra Raspberry atraves de USB, podemos leer estos valores con un script de Python con salida de el siguiente comando.

```
model = ser.read()
```

Para verificar el puerto serial en Raspberry donde est√° conectado el Arduino escriba en la terminal **dmesg | grep -i tty** con ese puerto necesitamos copiar el nombre en caso de que utilicemos una comunicaci√≥n en serie entre Nicla Sense ME y la Raspberry (esto es opcional, el objetivo de este proyecto es utilizar la comunicaci√≥n Bluetooth). 
Pero estamos intentando que sea inal√°mbrico, por lo que este c√≥digo que acabamos de modificar puede usarse como base para comenzar a mezclarlo con la biblioteca BLE que es compatible con la placa Arduino Nicla Sense Me. 
Al final encontrar√°s el c√≥digo base de la Placa Nicla para comunicar el Arduino con la Raspberry usando Bluepy.

Tambi√©n puedes usar el c√≥digo base para transmitir las variables para el modelo de forma inal√°mbrica, yo agregu√© un c√≥digo base python usando Bluepy para recibir los datos y usarlos como base para cualquier proyecto, adem√°s la plataforma Edge Impulse te permite cargar las bases de datos simplemente asegurate de que sean del mismo formato compatibles para este proyecto.

### C√≥digo para el Kit Arduino Nano RP2040 y Opl√° IoT

Puedes encontrar los c√≥digos de cada placa al final pero es necesario crear un archivo .h para cada una con las credenciales de tu WiFi. 
En Arduino hay una opci√≥n hasta el bot√≥n de abrir monitor serie que si haces clic en ella aparecer√° la funci√≥n desplegable y una de ellas es crear una nueva pesta√±a, crea una con el nombre de secrets.h y luego pondr√°s estas l√≠neas de c√≥digo:

```
const char WIFI_PASS[] = ""; //Password of the network  
``` 

Esto es necesario para los archivos de todas las placas que van a hacer que se pueda conectar adecuadamente usando WiFi NiNa.

Una cosa extra para el kit Arduino Opl√° IoT es repetir los mismos pasos y crear un archivo secrets.h uno para las credenciales y otro extra para la canci√≥n que incluye el buzzer en el Carrier, puedes crear tantas canciones como quieras, solo aseg√∫rate de ponerlo en el formato correcto como este que us√© con mi proyecto, ve a este [enlace](https://create.arduino.cc/editor/FT-CONTENT/37b7521c-325b-4868-b2c5-cf98cd2f0d45/preview?_gl=1*ml9iqj*_ga*MjAwOTE1MTc1NS4xNjcyNDE0MTQx*_ga_NEXN8H46L5*MTY3NTUzNDY1NS4xMDguMS4xNjc1NTM0ODI2LjAuMC4w) y copia el archivo pitches.h.

Tambien es necesario poner la direcci√≥n IP correspondiente a su broker en esta l√≠nea de c√≥digo y hacer lo mismo para el Arduino Nano RP2040: 
```
IPAddress server(192, 168, 0, 0);
```

<!-- Y una √∫ltima cosa que debo mencionar es que para cargar el c√≥digo debes instalar y configurar PlatformIO con el c√≥digo de Visual Studio, una vez que hayas hecho eso, carga el archivo Arduino BLE_model en Nicla Sense ME. Con esto estar√°s listo para utilizar el modelo de este proyecto con Bluetooth para enviar los resultados del clasificador a Python en Linux. ---->

Tambi√©n para cargar el c√≥digo tienes que instalar la biblioteca BHY2 1.0.4 que es la versi√≥n que us√© y que se ejecuta correctamente, luego tienes que ir a \libraries\Arduino_BHY2\src y buscar este archivo BoschSensortec.h, abrirlo y cambiar esto. 
valor:

```
#define WORK_BUFFER_SIZE    2048 
```
Cambiarlo por: 
```
#define WORK_BUFFER_SIZE    64   
```
Esto nos permite cargar apropiadamente nuestro modelo con la libreria BLE

## Workflow (Metodolog√≠a) Run the code

Antes de ejecutar el c√≥digo, me gustar√≠a explicar c√≥mo funciona. Repasemos el flujo de trabajo de Bluetooth. 
En el siguiente diagrama podemos ver que todo comienza con Nicla Sense Me usando el clasificador para detectar el movimiento, una vez hecho esto, lo enviar√° a trav√©s de Bluetooth a Raspberry, y el c√≥digo Python tomar√° esta entrada para escribir finalmente en el broker la Acci√≥n que reproducir√° los diferentes dispositivos y placas que se utilizan en el proyecto.

<center>
<img src="media_bot/10.png" width="60%">
</center>

<center>
<img src="media_bot/11.png" width="60%">
</center>

Ahora revisemos el flujo de trabajo MQTT que finaliza el proceso de este proyecto, despu√©s de recibir el mensaje en el broker, los Arduino se conectan, una vez que tienen alimentaci√≥n, y se suscriben al mismo "canal" para recibir el mensaje sobre el movimiento recibido. 
Ejecutan las instrucciones preparadas para ese movimiento, como mencion√© antes us√© un robot Lego, pero puedes crear el tuyo propio dependiendo de los recursos que tengas, la m√∫sica se puede reproducir con el Buzzer del Carrier, solo usando el dispositivo con Spotify o ambos.

<center>
<img src="media_bot/12.png" width="60%">
</center>

Una √∫ltima cosa que me gustar√≠a resaltar son las partes del c√≥digo que puedes comentar en caso de que est√©s usando una opci√≥n diferente para el robot o no est√©s usando robot y hayas agregado otro elemento en el proyecto, as√≠ que si ese es el caso, por favor coment, borra o reemplaza las siguientes l√≠neas:

```
from buildhat import Motor   
from buildhat import MotorPair   
right_arm = Motor('A') #define the port to connect the motor for the right arm   
left_arm = Motor('B')#define the port to connect the motor for the left arm   
def combo(): #movement of arms¬† ¬†    
	   print("Run combo")¬† ¬†    
	   right_arm.run_for_seconds(1.3, speed=-100)¬† ¬†    
	   left_arm.run_for_seconds(1.3, speed=100)   
def back():#back to initial position¬† ¬†    
	   print("Run back")¬† ¬†    
	   right_arm.run_for_seconds(1.3, speed=100)¬† ¬† ¬†   
	   left_arm.run_for_seconds(1.3, speed=-100)   
def both():#move arms at same time¬† ¬† ¬†   
	   print("Run both")¬† ¬† ¬†   
	   right_arm.run_for_seconds(3, speed=-100, blocking=False)¬† ¬† ¬†   
	   left_arm.run_for_seconds(3, speed=100, blocking=False)   
def backb():#move back arms at same time¬† ¬† ¬†   
	   print("Run backb")¬† ¬† ¬†   
	   right_arm.run_for_seconds(3, speed=100, blocking=False)¬† ¬† ¬†   
	   left_arm.run_for_seconds(3, speed=-100, blocking=False)   
#<----> in the if's there is a for for each one to move the motors of the LegoPi depending on the move   
#Comment all the for's in case you are not using Lego   
	   #for to move twice the robot arms¬† ¬†    
	   combo()¬† ¬†    
	   sleep(0.5)¬† ¬†    
	   back()¬† ¬†   
	   sleep(0.5)   
```

Y tambi√©n cambia la direcci√≥n IP para esta l√≠nea de c√≥digo, poniendo la IP correspondiente a la Raspberry.

```
broker_address = "192.168.xx.x" #put the ip from Raspberry as broker_address
```
Otro cambio en el codigo que debes hacer es cambiar la direcci√≥n MAC para la comunicaci√≥n Bluetooth entre los dispositivos, as√≠ que ve al archivo Python en la √∫ltima parte del c√≥digo y cambia la direcci√≥n de tu placa. 
Hay dos formas de hacerlo, una es con el archivo scanner.py adjunto en este repo es necesario para ejecutarlo desde la terminal en Raspberry, le mostrar√° los dispositivos disponibles y el otro es abrir el monitor serie en Arduino una vez que cargue el c√≥digo en Nicla de esta manera:

<center>
<img src="media_bot/14.png" width="60%">
</center>


Copia y pega el valor en la siguiente l√≠nea:

```
p = btle.Peripheral("1a:b4:c0:25:3a:aa")#use the scanner.py file to obtain this BLE address for the NICLA
```
Adem√°s, una √∫ltima edici√≥n de nuestro c√≥digo es la ruta del directorio de nuestros archivos multimedia que se van a reproducir. Edita o comenta estas l√≠neas dependiendo de si las va a utilizar o no. 

```
player= vlc.MediaPlayer('/home/pi/Desktop/media/model4/ink4.mp4') #CHANGE DIRECTORY 
```

Ahora que tenemos una idea clara sobre el proyecto completo, podemos ejecutar el c√≥digo.

## Mapping, iluminaci√≥n y esculturas inteligentes Script Running

El script es la base de interacci√≥n del usuario con mapeo, m√∫sica, iluminaci√≥n y escultura durante los movimientos realizados. El script ha sido desarrollado √≠ntegramente con Python adem√°s de una integraci√≥n de VLC, Spotify y MQTT, para una interacci√≥n m√°s intuitiva y sincr√≥nica. 
El script sirve como reproductor en tiempo real, activaci√≥n de luces, sonidos y esculturas a trav√©s del modelo entrenado que se despliega en el Arduino Nicla Sense ME, el cual env√≠a los datos por Bluetooth o conexi√≥n serial a un kit Opl√° IoT y Arduino Nano RP2040 Connect. 
Placa Arduino inal√°mbrica utilizando el corredor MQTT como elemento de traductor entre el usuario y el modelo. Si los archivos de media son diferenrtes a videos, ser√° necesario cambiar la ruta y el nombre del archivo. 

Podemos ejecutar el script para reproducir la animaci√≥n en el proyector y activar las luces como predice el modelo implementado(**antes de ejecutar el script, aseg√∫rese de que la ruta en la condici√≥n del script sea correcta**).

[![Demo Proyector](https://img.youtube.com/vi/_X0TFTJeD0U/0.jpg)](https://youtu.be/_X0TFTJeD0U?feature=shared)


Nota: Lo hice por separado ya que el proyector es prestado y no me dio tiempo de probar todos los elementos juntos, ya que pens√© que el robot no se apreciar√≠a en el video con poca iluminaci√≥n. 
El script que sirve de interfaz entre Raspberry, Arduino y los elementos utilizados es capaz de imprimir el estado del reproductor VLC as√≠ como la conexi√≥n MQTT no necesita conexi√≥n a internet, solo conectado al mismo router al que est√° conectado el Opl√°. 
La tarjeta Arduino Nano tambi√©n pueden funcionar en un hotspot de un tel√©fono inteligente. 
En general, la CPU del script podria requerir m√°s potencia si hay muchas ventanas de VLC abiertas, as√≠ que agrego una condici√≥n relacionada con el estado del reproductor para que cuando termine la animaci√≥n, el reproductor se cierre para reducir el uso de la CPU y evitar el uso innecesario de la CPU.
Ahora veamos un v√≠deo de c√≥mo funciona todo junto.

[![Demo Robot iteractivo](https://img.youtube.com/vi/FAeuIUkGI3k/0.jpg)](https://youtu.be/FAeuIUkGI3k?feature=shared)


Este fue mi proyecto con todos los recursos que tengo pero puede servir como base para crear algo m√°s grande. Me imagino algo como esto:

<center>
<img src="media_bot/17.gif" width="60%">
</center>

<center>
<img src="media_bot/18.gif" width="60%">
</center>

## Desaf√≠os con los que me encontr√© y lo que aprend√≠
- El principal desaf√≠o (una vez que aprend√≠ a crear el modelo con Edge Impulse) fue crear conexiones bluetooth sin tener mucho conocimiento sobre la biblioteca BLE, que us√© antes para otros proyectos de riego conexi√≥n WiFi usando la base de datos en tiempo real Firebase y MQTT. Es por eso que descubr√≠ que Mosquitto y Paho en Debian pueden resultar en las tecnolog√≠as m√°s adecuadas para abordar la conexi√≥n inal√°mbrica, de modo que pueda obtener control en tiempo real. Pero durante el desarrollo de este proyecto aprend√≠ mucho sobre Arduino Cloud y las conexiones con diferentes placas.
Observaciones sobre el proyecto
- La conexi√≥n Bluetooth tiene un n√∫mero limitado de dispositivos para conectar en Debian, solo permite 7 dispositivos usando bluetooth. Windows tiene 10 dispositivos, por lo que con muchos usuarios ser√° dif√≠cil usar bluetooth. Las recomendaciones utilizar√°n otro protocolo de comunicaci√≥n.
- Entrenar los movimientos puede ser dif√≠cil haciendo m√°s de 20 repeticiones de un movimiento, adem√°s me doy cuenta de que grabar los movimientos, es necesario ser muy preciso al realizar los movimientos, la diferencia en cada repetici√≥n afecta la precisi√≥n del modelo. Para tener una base fuerte para el modelo la recomendaci√≥n es tener al menos 20 repeticiones de cada movimiento y 10 al menos para la prueba del modelo en la plataforma Edge Impulse. Adem√°s, despu√©s de 3 movimientos podemos encontrarnos con problemas como clasificaci√≥n err√≥nea. Despu√©s de 3 movimientos, tenemos que ser muy creativos para hacer los movimientos lo menos similares posible en t√©rminos de variables, especialmente con el aceler√≥metro y el giroscopio.

## Logros de los que estoy orgulloso

- Crear un script personalizado para cambiar solo algunas variables
- Env√≠o de datos usando la biblioteca BLE a mi dispositivo Linux usando Python
- Env√≠o de mensajes a un Arduino Nano y Arduino MRK1010 usando MQTT
- Aprendiendo nuevas tecnolog√≠as en un tiempo r√©cord
- Comience a crear una herramienta que ayudar√° a otros

## ¬øQu√© sigue para el proyecto?

- Desarrollar su propio dispositivo integrado para la implementaci√≥n del modelo (que ya deber√≠a incluir un aceler√≥metro, giroscopio y una conexi√≥n wifi)
- Mejorar la adquisici√≥n de datos del usuario a trav√©s del aceler√≥metro y giroscopio.
- Agregue grabaci√≥n Bluetooth de todas las variables utilizadas en este proyecto y h√°galas compatibles con la plataforma Edge Impulse.
- Implementar en un museo, o presentaci√≥n de arte (tambi√©n en mi casa para futuros proyectos)
- Agregue esculturas cin√©ticas con impresi√≥n 3D usando servomotores y motores DC para agregar un efecto como el de la pel√≠cula Matilda.
- Prototipo de prueba con bailarina.
- Agrega efectos m√°gicos y agrega m√°s efectos visuales con las animaciones.

